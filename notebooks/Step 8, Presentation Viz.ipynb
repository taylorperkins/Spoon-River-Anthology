{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import networkx as nx\n",
    "import nxviz as nv\n",
    "import pandas as pd\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 219  # william goode\n",
    "p2 = 20  # Minerva Jones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43, 129 --> 0.5663854115643483\n",
    "\n",
    "Main goal of this notebook is just to create nice viz of the different points of the graph throughout it's lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_graph = nx.read_gpickle(f'../data/combined_graphs/{p2}/{p1}.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({18208: {'doc_id': -1, 'tf_idf': -1, 'term_id': 1302, 'type': 'SYN'}, 17580: {'doc_id': -1, 'tf_idf': -1, 'term_id': 674, 'type': 'SYN'}, 17283: {'doc_id': -1, 'tf_idf': -1, 'term_id': 377, 'type': 'SYN'}, 21392: {'doc_id': -1, 'tf_idf': -1, 'term_id': 4486, 'type': 'SYN'}, 22438: {'doc_id': -1, 'tf_idf': -1, 'term_id': 5532, 'type': 'SYN'}, 22439: {'doc_id': -1, 'tf_idf': -1, 'term_id': 5533, 'type': 'SYN'}, 22440: {'doc_id': -1, 'tf_idf': -1, 'term_id': 5534, 'type': 'SYN'}, 22442: {'doc_id': -1, 'tf_idf': -1, 'term_id': 5536, 'type': 'SYN'}, 17051: {'doc_id': -1, 'tf_idf': -1, 'term_id': 145, 'type': 'SYN'}, 19360: {'doc_id': -1, 'tf_idf': -1, 'term_id': 2454, 'type': 'SYN'}, 1163: {'doc_id': 20, 'tf_idf': 0.01355990646613538, 'term_id': 61, 'type': 'SPA'}, 1169: {'doc_id': 20, 'tf_idf': 0.15764392225410856, 'term_id': 396, 'type': 'SPA'}, 1176: {'doc_id': 20, 'tf_idf': 0.15191470865798798, 'term_id': 1383, 'type': 'SPA'}, 1188: {'doc_id': 20, 'tf_idf': 0.37957527558217335, 'term_id': 3749, 'type': 'SPA'}, 1194: {'doc_id': 20, 'tf_idf': 0.18978763779108668, 'term_id': 3755, 'type': 'SPA'}, 1199: {'doc_id': 20, 'tf_idf': 0.16589247994611142, 'term_id': 3760, 'type': 'SPA'}, 13355: {'doc_id': 219, 'tf_idf': 0.014904798103809097, 'term_id': 61, 'type': 'SPA'}, 13370: {'doc_id': 219, 'tf_idf': 0.08663964015379098, 'term_id': 396, 'type': 'SPA'}, 13352: {'doc_id': 219, 'tf_idf': 0.05283955875736931, 'term_id': 21, 'type': 'SPA'}, 13365: {'doc_id': 219, 'tf_idf': 0.14762534869317062, 'term_id': 319, 'type': 'SPA'}, 13383: {'doc_id': 219, 'tf_idf': 0.14071671976304573, 'term_id': 3699, 'type': 'SPA'}, 13392: {'doc_id': 219, 'tf_idf': 0.15608082714173596, 'term_id': 3773, 'type': 'SPA'}, 13395: {'doc_id': 219, 'tf_idf': 0.41722211446510055, 'term_id': 3776, 'type': 'SPA'}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_graph.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_names = pickle.load(open('../data/chapter_names.p', 'rb'))\n",
    "spa_dictionary = Dictionary.load('../data/spa.dict')\n",
    "syn_dictionary = Dictionary.load('../data/syn.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, data in p_graph.nodes(data=True):\n",
    "    # it's a synonym node\n",
    "    if data['type'] == 'SYN':\n",
    "        data['document'] = 'Synonym'\n",
    "        data['term'] = syn_dictionary[data['term_id']]\n",
    "        \n",
    "    else:\n",
    "        data['document'] = chapter_names[data['doc_id']]\n",
    "        data['term'] = spa_dictionary[data['term_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_graph.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_graph = nx.relabel_nodes(\n",
    "    p_graph,\n",
    "    {node: f\"{node}: {data['term']}\" for node, data in p_graph.nodes(data=True)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 8)\n",
    "\n",
    "ap = nv.CircosPlot(\n",
    "    p_graph, \n",
    "    node_color='doc_id', \n",
    "    node_grouping='document', \n",
    "    group_label_position='middle',\n",
    "    group_label_color=True,\n",
    "    node_labels=True, \n",
    "    node_label_layout=\"numbers\",\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "\n",
    "ap.draw_group_labels()\n",
    "\n",
    "ap.draw()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/full_similarities.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of triangle relationships\n",
    "total_relationships = 0\n",
    "for node, data in p_graph.nodes(data=True):\n",
    "    if data['type'] == 'SYN':\n",
    "        num_p1_nodes = 0\n",
    "        num_p2_nodes = 0\n",
    "        \n",
    "        for neighbor in p_graph.neighbors(node):\n",
    "            if p_graph.node[neighbor]['doc_id'] == 219:\n",
    "                num_p1_nodes += 1\n",
    "            else:\n",
    "                num_p2_nodes += 1\n",
    "        \n",
    "        total_relationships += (num_p1_nodes * num_p2_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct relationships\n",
    "dr_nodes = [\n",
    "    node for node, data in p_graph.nodes(data=True)\n",
    "    if data['type'] == 'SPA'\n",
    "    and 'SPA' in [p_graph.node[neighbor]['type'] for neighbor in p_graph.neighbors(node)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = nv.ArcPlot(\n",
    "    p_graph.subgraph(dr_nodes),\n",
    "    node_color='doc_id', \n",
    "    node_grouping='document', \n",
    "    group_label_position='middle',\n",
    "    group_label_color=True,\n",
    "    node_labels=True, \n",
    "    node_label_layout=\"numbers\",\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "\n",
    "ap.draw()\n",
    "plt.savefig('../data/direct_relationship.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_graph.subgraph(dr_nodes).nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_nodes = set()\n",
    "\n",
    "for node, data in p_graph.nodes(data=True):\n",
    "    if data['type'] == 'SYN':\n",
    "        syn_nodes.add(node)\n",
    "        \n",
    "        for neighbor in p_graph.neighbors(node):\n",
    "            syn_nodes.add(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = nv.ArcPlot(\n",
    "    p_graph.subgraph(list(syn_nodes)),\n",
    "    node_color='doc_id', \n",
    "    node_grouping='document', \n",
    "    group_label_position='middle',\n",
    "    group_label_color=True,\n",
    "    node_labels=True, \n",
    "    node_label_layout=\"numbers\",\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "\n",
    "ap.draw()\n",
    "plt.title('Test title')\n",
    "plt.savefig('../data/synonyms.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_p1 = nx.read_gpickle(f'../data/base_graphs/{p1}.gpickle')\n",
    "base_p2 = nx.read_gpickle(f'../data/base_graphs/{p2}.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_nodes_p1 = set()\n",
    "spa_nodes_p2 = set()\n",
    "\n",
    "for node, data in p_graph.nodes(data=True):\n",
    "    if data['doc_id'] == p1:\n",
    "        spa_nodes_p1.add(data['term_id'])\n",
    "    elif data['doc_id'] == p2:\n",
    "        spa_nodes_p2.add(data['term_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_p1_uncontributing_nodes = [\n",
    "    data['term_id'] for node, data in base_p1.nodes(data=True)\n",
    "    if data['type'] == 'SPA' \n",
    "    and data['term_id'] not in spa_nodes_p1\n",
    "]\n",
    "\n",
    "base_p2_uncontributing_nodes = [\n",
    "    data['term_id'] for node, data in base_p2.nodes(data=True)\n",
    "    if data['type'] == 'SPA' \n",
    "    and data['term_id'] not in spa_nodes_p2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_dict = Dictionary.load('../data/spa.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncontributing_terms = list()\n",
    "for node_list in [base_p1_uncontributing_nodes, base_p2_uncontributing_nodes]:\n",
    "    for term_id in node_list:\n",
    "        uncontributing_terms.append(spa_dict[term_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "text = ' '.join(uncontributing_terms)\n",
    "\n",
    "# # Generate a word cloud image\n",
    "# wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('../data/uncontributing_wordcloud.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
